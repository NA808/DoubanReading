import pandas as pd
import numpy as np
import torch
import gc
import os
import shutil
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report
from transformers import (
    BertTokenizer,
    BertForSequenceClassification,
    Trainer,
    TrainingArguments,
    EarlyStoppingCallback
)
from datasets import Dataset


def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    report = classification_report(labels, preds, output_dict=True)
    return {
        'accuracy': report['accuracy'],
        'precision': report['weighted avg']['precision'],
        'recall': report['weighted avg']['recall'],
        'f1': report['weighted avg']['f1-score']
    }


def prepare_data(texts, labels, tokenizer, max_length=512):
    """ä¼˜åŒ– Dataset å¤„ç†ï¼Œå‡å°‘å†…å­˜å ç”¨"""
    encodings = tokenizer(
        texts, truncation=True, padding=True, max_length=max_length
    )
    dataset = Dataset.from_dict({
        'input_ids': encodings['input_ids'],
        'attention_mask': encodings['attention_mask'],
        'labels': labels
    })
    return dataset.map(lambda x: x, batched=True, batch_size=64)  # æ‰¹é‡å¤„ç†


def release_memory():
    """é‡Šæ”¾ GPU å’Œ CPU å†…å­˜"""
    torch.cuda.empty_cache()
    gc.collect()


def stratified_cross_validation(
        df,
        model_path='/home/roberta-model',
        n_splits=5,
        epochs=5,
        batch_size=16
):
    df['æƒ…æ„Ÿæ ‡ç­¾'] = df['æƒ…æ„Ÿæ ‡ç­¾'].astype(int)
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    best_f1 = 0
    best_model_path = None
    best_metrics = {}
    tokenizer = BertTokenizer.from_pretrained(model_path)

    for fold, (train_index, val_index) in enumerate(skf.split(df['è¯„è®ºå†…å®¹'], df['æƒ…æ„Ÿæ ‡ç­¾']), 1):
        print(f"\n===== è®­ç»ƒç¬¬ {fold} æŠ˜ =====")

        train_texts = df.iloc[train_index]['è¯„è®ºå†…å®¹'].astype(str).tolist()  # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
        train_labels = df.iloc[train_index]['æƒ…æ„Ÿæ ‡ç­¾'].tolist()
        val_texts = df.iloc[val_index]['è¯„è®ºå†…å®¹'].astype(str).tolist()  # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
        val_labels = df.iloc[val_index]['æƒ…æ„Ÿæ ‡ç­¾'].tolist()

        train_dataset = prepare_data(train_texts, train_labels, tokenizer)
        val_dataset = prepare_data(val_texts, val_labels, tokenizer)

        model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)

        training_args = TrainingArguments(
            output_dir=f'/home/results/fold_{fold}',
            save_total_limit=1,  # åªä¿å­˜æœ€è¿‘ 1 ä¸ª checkpoint
            save_strategy="epoch",
            evaluation_strategy="epoch",
            load_best_model_at_end=True,
            metric_for_best_model="f1",
            num_train_epochs=epochs,
            per_device_train_batch_size=batch_size,
            per_device_eval_batch_size=batch_size,
            warmup_steps=500,
            weight_decay=0.01,
            learning_rate=2e-5,
            logging_dir=f'/home/logs/fold_{fold}',
            logging_steps=10,
            fp16=True,  # ä½¿ç”¨æ··åˆç²¾åº¦åŠ é€Ÿ
            report_to=["none"]
        )

        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            compute_metrics=compute_metrics,
            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]
        )

        trainer.train()
        eval_results = trainer.evaluate()

        # è®°å½•æœ€ä½³æ¨¡å‹
        f1_score = eval_results['eval_f1']
        if f1_score > best_f1:
            best_f1 = f1_score
            best_model_path = f'/home/best_sentiment_model'
            best_metrics = {
                'accuracy': eval_results['eval_accuracy'],
                'precision': eval_results['eval_precision'],
                'recall': eval_results['eval_recall'],
                'f1': eval_results['eval_f1']
            }

            # æ¯æ¬¡æ‰¾åˆ°æ›´å¥½çš„æ¨¡å‹å°±ç›´æ¥è¦†ç›–ä¿å­˜
            trainer.save_model(best_model_path)

        # é‡Šæ”¾ GPU å’Œ CPU å†…å­˜
        del model, trainer, train_dataset, val_dataset
        release_memory()

    # è¾“å‡ºæœ€ä¼˜æ¨¡å‹çš„è¯¦ç»†æŒ‡æ ‡
    if best_model_path:
        print("\nğŸ† æœ€ç»ˆæœ€ä¼˜æ¨¡å‹è¯„ä¼°ç»“æœï¼š")
        print(f"  - æ¨¡å‹ä¿å­˜è·¯å¾„: {best_model_path}")
        print(f"  - å‡†ç¡®ç‡ (Accuracy): {best_metrics['accuracy']:.4f}")
        print(f"  - ç²¾ç¡®ç‡ (Precision): {best_metrics['precision']:.4f}")
        print(f"  - å¬å›ç‡ (Recall): {best_metrics['recall']:.4f}")
        print(f"  - F1 åˆ†æ•° (F1-score): {best_metrics['f1']:.4f}")

    return best_model_path, best_metrics



def main():
    df = pd.read_excel('/home/dataset.xlsx')
    df = df[['è¯„è®ºå†…å®¹', 'æƒ…æ„Ÿæ ‡ç­¾']]
    df.dropna(inplace=True)
    df = df[~df['è¯„è®ºå†…å®¹'].astype(str).str.isnumeric()]

    stratified_cross_validation(df)


if __name__ == '__main__':
    main()