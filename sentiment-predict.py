import pandas as pd
import torch
from transformers import BertTokenizer, BertForSequenceClassification


def predict_sentiment(texts, model, tokenizer, device, batch_size=16):
    """
    æ‰¹é‡è¿›è¡Œæƒ…æ„Ÿé¢„æµ‹

    å‚æ•°:
    - texts: å¾…é¢„æµ‹çš„æ–‡æœ¬åˆ—è¡¨
    - model: é¢„è®­ç»ƒçš„BERTæ¨¡å‹
    - tokenizer: æ–‡æœ¬ç¼–ç å™¨
    - device: è®¡ç®—è®¾å¤‡(CPU/GPU)
    - batch_size: æ¯æ‰¹æ¬¡å¤„ç†çš„æ–‡æœ¬æ•°é‡

    è¿”å›:
    é¢„æµ‹çš„æƒ…æ„Ÿæ ‡ç­¾åˆ—è¡¨
    """
    predictions = []

    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i + batch_size]

        # æ–‡æœ¬ç¼–ç 
        encodings = tokenizer(
            batch_texts,
            padding=True,
            truncation=True,
            max_length=512,
            return_tensors="pt"
        )

        input_ids = encodings["input_ids"].to(device)
        attention_mask = encodings["attention_mask"].to(device)

        with torch.no_grad():
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask
            )
            batch_predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()
            predictions.extend(batch_predictions)

    return predictions


def main():
    # è®¾å¤‡æ£€æµ‹ï¼šå¦‚æœæ”¯æŒ GPU + FP16ï¼Œåˆ™ä½¿ç”¨ FP16ï¼Œå¦åˆ™ä½¿ç”¨ FP32
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

    # æ¨¡å‹å’Œåˆ†è¯å™¨è·¯å¾„
    model_path = "/home/best_sentiment_model"

    print(f"ğŸ” å¼€å§‹åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨...")

    # åŠ è½½ Tokenizer å’Œè®­ç»ƒå¥½çš„ BERT æ¨¡å‹
    tokenizer = BertTokenizer.from_pretrained("/home/roberta-model")
    model = BertForSequenceClassification.from_pretrained(
        model_path,
        num_labels=2,  # äºŒåˆ†ç±»
        torch_dtype=torch_dtype
    ).to(device)

    # è¿›å…¥æ¨ç†æ¨¡å¼ï¼Œå‡å°‘æ˜¾å­˜å ç”¨
    model.eval()

    # è¯»å–æœªæ ‡æ³¨æ•°æ®
    input_file = "/home/combined_comments.xlsx"
    print(f"ğŸ“– è¯»å–è¾“å…¥æ–‡ä»¶: {input_file}")

    df = pd.read_excel(input_file)

    # åˆ é™¤ç©ºå€¼
    df.dropna(subset=['è¯„è®ºå†…å®¹'], inplace=True)

    # è¿‡æ»¤æ‰ç©ºå­—ç¬¦ä¸²
    df = df[df['è¯„è®ºå†…å®¹'].str.strip() != '']

    texts = df["è¯„è®ºå†…å®¹"].tolist()

    print(f"ğŸ“Š å‡†å¤‡é¢„æµ‹ {len(texts)} æ¡è¯„è®º...")

    # è¿›è¡Œæƒ…æ„Ÿé¢„æµ‹
    df["æƒ…æ„Ÿæ ‡ç­¾"] = predict_sentiment(
        texts,
        model,
        tokenizer,
        device,
        batch_size=16
    )

    # ä¿å­˜ç»“æœï¼ˆç§»é™¤ encoding å‚æ•°ï¼‰
    output_file = "/home/predicted_sentiments.xlsx"
    df.to_excel(output_file, index=False)

    print(f"âœ… é¢„æµ‹å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ {output_file}")
    print(f"   æ€»è¯„è®ºæ•°: {len(texts)}")
    print(f"   æ­£å‘æƒ…æ„Ÿ: {sum(df['æƒ…æ„Ÿæ ‡ç­¾'] == 1)}")
    print(f"   è´Ÿå‘æƒ…æ„Ÿ: {sum(df['æƒ…æ„Ÿæ ‡ç­¾'] == 0)}")


if __name__ == "__main__":
    main()